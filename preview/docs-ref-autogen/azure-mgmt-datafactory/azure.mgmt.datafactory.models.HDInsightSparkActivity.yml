### YamlMime:PythonClass
uid: azure.mgmt.datafactory.models.HDInsightSparkActivity
name: HDInsightSparkActivity
fullName: azure.mgmt.datafactory.models.HDInsightSparkActivity
module: azure.mgmt.datafactory.models
inheritances:
- azure.mgmt.datafactory.models._models_py3.ExecutionActivity
summary: 'HDInsight Spark activity.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'HDInsightSparkActivity(*, name: str, root_path: collections.abc.MutableMapping[str,
    Any], entry_file_path: collections.abc.MutableMapping[str, Any], additional_properties:
    Optional[Dict[str, collections.abc.MutableMapping[str, Any]]] = None, description:
    Optional[str] = None, depends_on: Optional[List[_models.ActivityDependency]] =
    None, user_properties: Optional[List[_models.UserProperty]] = None, linked_service_name:
    Optional[_models.LinkedServiceReference] = None, policy: Optional[_models.ActivityPolicy]
    = None, arguments: Optional[List[collections.abc.MutableMapping[str, Any]]] =
    None, get_debug_info: Optional[Union[str, _models.HDInsightActivityDebugInfoOption]]
    = None, spark_job_linked_service: Optional[_models.LinkedServiceReference] = None,
    class_name: Optional[str] = None, proxy_user: Optional[collections.abc.MutableMapping[str,
    Any]] = None, spark_config: Optional[Dict[str, collections.abc.MutableMapping[str,
    Any]]] = None, **kwargs: Any)'
variables:
- description: 'Unmatched properties from the message are deserialized to this

    collection.'
  name: additional_properties
  types:
  - <xref:dict>[<xref:str>, <xref:JSON>]
- description: Activity name. Required.
  name: name
  types:
  - <xref:str>
- description: Type of activity. Required.
  name: type
  types:
  - <xref:str>
- description: Activity description.
  name: description
  types:
  - <xref:str>
- description: Activity depends on condition.
  name: depends_on
  types:
  - <xref:list>[<xref:azure.mgmt.datafactory.models.ActivityDependency>]
- description: Activity user properties.
  name: user_properties
  types:
  - <xref:list>[<xref:azure.mgmt.datafactory.models.UserProperty>]
- description: Linked service reference.
  name: linked_service_name
  types:
  - <xref:azure.mgmt.datafactory.models.LinkedServiceReference>
- description: Activity policy.
  name: policy
  types:
  - <xref:azure.mgmt.datafactory.models.ActivityPolicy>
- description: 'The root path in ''sparkJobLinkedService'' for all the job''s files.
    Type: string

    (or Expression with resultType string). Required.'
  name: root_path
  types:
  - <xref:JSON>
- description: 'The relative path to the root folder of the code/package to be executed.

    Type: string (or Expression with resultType string). Required.'
  name: entry_file_path
  types:
  - <xref:JSON>
- description: The user-specified arguments to HDInsightSparkActivity.
  name: arguments
  types:
  - <xref:list>[<xref:JSON>]
- description: 'Debug info option. Known values are: "None", "Always", and "Failure".'
  name: get_debug_info
  types:
  - <xref:str>
  - <xref:azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption>
- description: 'The storage linked service for uploading the entry file and

    dependencies, and for receiving logs.'
  name: spark_job_linked_service
  types:
  - <xref:azure.mgmt.datafactory.models.LinkedServiceReference>
- description: The application's Java/Spark main class.
  name: class_name
  types:
  - <xref:str>
- description: 'The user to impersonate that will execute the job. Type: string (or

    Expression with resultType string).'
  name: proxy_user
  types:
  - <xref:JSON>
- description: Spark configuration property.
  name: spark_config
  types:
  - <xref:dict>[<xref:str>, <xref:JSON>]
